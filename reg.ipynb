{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run bert\n",
    "%run utils.ipynb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn import linear_model \n",
    "from sklearn.metrics import cohen_kappa_score,mean_absolute_error,mean_squared_error,accuracy_score,explained_variance_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions  \n",
       "0     3.5         3.0          3.0      4.0          3.0  \n",
       "1     2.5         3.0          2.0      2.0          2.5  \n",
       "2     3.5         3.0          3.0      3.0          2.5  \n",
       "3     4.5         4.5          4.5      4.0          5.0  \n",
       "4     3.0         3.0          3.0      2.5          2.5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "d = loader.GetData('L2Writing')\n",
    "#d = loader.GetShuffled()\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIGA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:745: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  attention_scores = torch.bmm(query_layer, key_layer.transpose(-1, -2)) / torch.tensor(\n",
      "c:\\Users\\GIGA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:829: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score += c2p_att / torch.tensor(scale, dtype=c2p_att.dtype)\n",
      "c:\\Users\\GIGA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\deberta_v2\\modeling_deberta_v2.py:852: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  score += p2c_att / torch.tensor(scale, dtype=p2c_att.dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1500, run:0\n",
      "10/1500, run:0\n",
      "20/1500, run:0\n",
      "30/1500, run:0\n",
      "40/1500, run:0\n",
      "50/1500, run:0\n",
      "60/1500, run:0\n",
      "70/1500, run:0\n",
      "80/1500, run:0\n",
      "90/1500, run:0\n",
      "100/1500, run:0\n",
      "110/1500, run:0\n",
      "120/1500, run:0\n",
      "130/1500, run:0\n",
      "140/1500, run:0\n",
      "150/1500, run:0\n",
      "160/1500, run:0\n",
      "170/1500, run:0\n",
      "180/1500, run:0\n",
      "190/1500, run:0\n",
      "200/1500, run:0\n",
      "210/1500, run:0\n",
      "220/1500, run:0\n",
      "230/1500, run:0\n",
      "240/1500, run:0\n",
      "250/1500, run:0\n",
      "260/1500, run:0\n",
      "270/1500, run:0\n",
      "280/1500, run:0\n",
      "290/1500, run:0\n",
      "300/1500, run:0\n",
      "310/1500, run:0\n",
      "320/1500, run:0\n",
      "330/1500, run:0\n",
      "340/1500, run:0\n",
      "350/1500, run:0\n",
      "360/1500, run:0\n",
      "370/1500, run:0\n",
      "380/1500, run:0\n",
      "390/1500, run:0\n",
      "400/1500, run:0\n",
      "410/1500, run:0\n",
      "420/1500, run:0\n",
      "430/1500, run:0\n",
      "440/1500, run:0\n",
      "450/1500, run:0\n",
      "460/1500, run:0\n",
      "470/1500, run:0\n",
      "480/1500, run:0\n",
      "490/1500, run:0\n",
      "500/1500, run:0\n",
      "510/1500, run:0\n",
      "520/1500, run:0\n",
      "530/1500, run:0\n",
      "540/1500, run:0\n",
      "550/1500, run:0\n",
      "560/1500, run:0\n",
      "570/1500, run:0\n",
      "580/1500, run:0\n",
      "590/1500, run:0\n",
      "600/1500, run:0\n",
      "610/1500, run:0\n",
      "620/1500, run:0\n",
      "630/1500, run:0\n",
      "640/1500, run:0\n",
      "650/1500, run:0\n",
      "660/1500, run:0\n",
      "670/1500, run:0\n",
      "680/1500, run:0\n",
      "690/1500, run:0\n",
      "700/1500, run:0\n",
      "710/1500, run:0\n",
      "720/1500, run:0\n",
      "730/1500, run:0\n",
      "740/1500, run:0\n",
      "750/1500, run:0\n",
      "760/1500, run:0\n",
      "770/1500, run:0\n",
      "780/1500, run:0\n",
      "790/1500, run:0\n",
      "800/1500, run:0\n",
      "810/1500, run:0\n",
      "820/1500, run:0\n",
      "830/1500, run:0\n",
      "840/1500, run:0\n",
      "850/1500, run:0\n",
      "860/1500, run:0\n",
      "870/1500, run:0\n",
      "880/1500, run:0\n",
      "890/1500, run:0\n",
      "900/1500, run:0\n",
      "910/1500, run:0\n",
      "920/1500, run:0\n",
      "930/1500, run:0\n",
      "940/1500, run:0\n",
      "950/1500, run:0\n",
      "960/1500, run:0\n",
      "970/1500, run:0\n",
      "980/1500, run:0\n",
      "990/1500, run:0\n",
      "1000/1500, run:0\n",
      "1010/1500, run:0\n",
      "1020/1500, run:0\n",
      "1030/1500, run:0\n",
      "1040/1500, run:0\n",
      "1050/1500, run:0\n",
      "1060/1500, run:0\n",
      "1070/1500, run:0\n",
      "1080/1500, run:0\n",
      "1090/1500, run:0\n",
      "1100/1500, run:0\n",
      "1110/1500, run:0\n",
      "1120/1500, run:0\n",
      "1130/1500, run:0\n",
      "1140/1500, run:0\n",
      "1150/1500, run:0\n",
      "1160/1500, run:0\n",
      "1170/1500, run:0\n",
      "1180/1500, run:0\n",
      "1190/1500, run:0\n",
      "1200/1500, run:0\n",
      "1210/1500, run:0\n",
      "1220/1500, run:0\n",
      "1230/1500, run:0\n",
      "1240/1500, run:0\n",
      "1250/1500, run:0\n",
      "1260/1500, run:0\n",
      "1270/1500, run:0\n",
      "1280/1500, run:0\n",
      "1290/1500, run:0\n",
      "1300/1500, run:0\n",
      "1310/1500, run:0\n",
      "1320/1500, run:0\n",
      "1330/1500, run:0\n",
      "1340/1500, run:0\n",
      "1350/1500, run:0\n",
      "1360/1500, run:0\n",
      "1370/1500, run:0\n",
      "1380/1500, run:0\n",
      "1390/1500, run:0\n",
      "1400/1500, run:0\n",
      "1410/1500, run:0\n",
      "1420/1500, run:0\n",
      "1430/1500, run:0\n",
      "1440/1500, run:0\n",
      "1450/1500, run:0\n",
      "1460/1500, run:0\n",
      "1470/1500, run:0\n",
      "1480/1500, run:0\n",
      "1490/1500, run:0\n",
      "0/1500, run:1\n",
      "10/1500, run:1\n",
      "20/1500, run:1\n",
      "30/1500, run:1\n",
      "40/1500, run:1\n",
      "50/1500, run:1\n",
      "60/1500, run:1\n",
      "70/1500, run:1\n",
      "80/1500, run:1\n",
      "90/1500, run:1\n",
      "100/1500, run:1\n",
      "110/1500, run:1\n",
      "120/1500, run:1\n",
      "130/1500, run:1\n",
      "140/1500, run:1\n",
      "150/1500, run:1\n",
      "160/1500, run:1\n",
      "170/1500, run:1\n",
      "180/1500, run:1\n",
      "190/1500, run:1\n",
      "200/1500, run:1\n",
      "210/1500, run:1\n",
      "220/1500, run:1\n",
      "230/1500, run:1\n",
      "240/1500, run:1\n",
      "250/1500, run:1\n",
      "260/1500, run:1\n",
      "270/1500, run:1\n",
      "280/1500, run:1\n",
      "290/1500, run:1\n",
      "300/1500, run:1\n",
      "310/1500, run:1\n",
      "320/1500, run:1\n",
      "330/1500, run:1\n",
      "340/1500, run:1\n",
      "350/1500, run:1\n",
      "360/1500, run:1\n",
      "370/1500, run:1\n",
      "380/1500, run:1\n",
      "390/1500, run:1\n",
      "400/1500, run:1\n",
      "410/1500, run:1\n",
      "420/1500, run:1\n",
      "430/1500, run:1\n",
      "440/1500, run:1\n",
      "450/1500, run:1\n",
      "460/1500, run:1\n",
      "470/1500, run:1\n",
      "480/1500, run:1\n",
      "490/1500, run:1\n",
      "500/1500, run:1\n",
      "510/1500, run:1\n",
      "520/1500, run:1\n",
      "530/1500, run:1\n",
      "540/1500, run:1\n",
      "550/1500, run:1\n",
      "560/1500, run:1\n",
      "570/1500, run:1\n",
      "580/1500, run:1\n",
      "590/1500, run:1\n",
      "600/1500, run:1\n",
      "610/1500, run:1\n",
      "620/1500, run:1\n",
      "630/1500, run:1\n",
      "640/1500, run:1\n",
      "650/1500, run:1\n",
      "660/1500, run:1\n",
      "670/1500, run:1\n",
      "680/1500, run:1\n",
      "690/1500, run:1\n",
      "700/1500, run:1\n",
      "710/1500, run:1\n",
      "720/1500, run:1\n",
      "730/1500, run:1\n",
      "740/1500, run:1\n",
      "750/1500, run:1\n",
      "760/1500, run:1\n",
      "770/1500, run:1\n",
      "780/1500, run:1\n",
      "790/1500, run:1\n",
      "800/1500, run:1\n",
      "810/1500, run:1\n",
      "820/1500, run:1\n",
      "830/1500, run:1\n",
      "840/1500, run:1\n",
      "850/1500, run:1\n",
      "860/1500, run:1\n",
      "870/1500, run:1\n",
      "880/1500, run:1\n",
      "890/1500, run:1\n",
      "900/1500, run:1\n",
      "910/1500, run:1\n",
      "920/1500, run:1\n",
      "930/1500, run:1\n",
      "940/1500, run:1\n",
      "950/1500, run:1\n",
      "960/1500, run:1\n",
      "970/1500, run:1\n",
      "980/1500, run:1\n",
      "990/1500, run:1\n",
      "1000/1500, run:1\n",
      "1010/1500, run:1\n",
      "1020/1500, run:1\n",
      "1030/1500, run:1\n",
      "1040/1500, run:1\n",
      "1050/1500, run:1\n",
      "1060/1500, run:1\n",
      "1070/1500, run:1\n",
      "1080/1500, run:1\n",
      "1090/1500, run:1\n",
      "1100/1500, run:1\n",
      "1110/1500, run:1\n",
      "1120/1500, run:1\n",
      "1130/1500, run:1\n",
      "1140/1500, run:1\n",
      "1150/1500, run:1\n",
      "1160/1500, run:1\n",
      "1170/1500, run:1\n",
      "1180/1500, run:1\n",
      "1190/1500, run:1\n",
      "1200/1500, run:1\n",
      "1210/1500, run:1\n",
      "1220/1500, run:1\n",
      "1230/1500, run:1\n",
      "1240/1500, run:1\n",
      "1250/1500, run:1\n",
      "1260/1500, run:1\n",
      "1270/1500, run:1\n",
      "1280/1500, run:1\n",
      "1290/1500, run:1\n",
      "1300/1500, run:1\n",
      "1310/1500, run:1\n",
      "1320/1500, run:1\n",
      "1330/1500, run:1\n",
      "1340/1500, run:1\n",
      "1350/1500, run:1\n",
      "1360/1500, run:1\n",
      "1370/1500, run:1\n",
      "1380/1500, run:1\n",
      "1390/1500, run:1\n",
      "1400/1500, run:1\n",
      "1410/1500, run:1\n",
      "1420/1500, run:1\n",
      "1430/1500, run:1\n",
      "1440/1500, run:1\n",
      "1450/1500, run:1\n",
      "1460/1500, run:1\n",
      "1470/1500, run:1\n",
      "1480/1500, run:1\n",
      "1490/1500, run:1\n",
      "3000/1500, run:f\n",
      "3010/1500, run:f\n",
      "3020/1500, run:f\n",
      "3030/1500, run:f\n",
      "3040/1500, run:f\n",
      "3050/1500, run:f\n",
      "3060/1500, run:f\n",
      "3070/1500, run:f\n",
      "3080/1500, run:f\n",
      "3090/1500, run:f\n",
      "3100/1500, run:f\n",
      "3110/1500, run:f\n",
      "3120/1500, run:f\n",
      "3130/1500, run:f\n",
      "3140/1500, run:f\n",
      "3150/1500, run:f\n",
      "3160/1500, run:f\n",
      "3170/1500, run:f\n",
      "3180/1500, run:f\n",
      "3190/1500, run:f\n",
      "3200/1500, run:f\n",
      "3210/1500, run:f\n",
      "3220/1500, run:f\n",
      "3230/1500, run:f\n",
      "3240/1500, run:f\n",
      "3250/1500, run:f\n",
      "3260/1500, run:f\n",
      "3270/1500, run:f\n",
      "3280/1500, run:f\n",
      "3290/1500, run:f\n",
      "3300/1500, run:f\n",
      "3310/1500, run:f\n",
      "3320/1500, run:f\n",
      "3330/1500, run:f\n",
      "3340/1500, run:f\n",
      "3350/1500, run:f\n",
      "3360/1500, run:f\n",
      "3370/1500, run:f\n",
      "3380/1500, run:f\n",
      "3390/1500, run:f\n",
      "3400/1500, run:f\n",
      "3410/1500, run:f\n",
      "3420/1500, run:f\n",
      "3430/1500, run:f\n",
      "3440/1500, run:f\n",
      "3450/1500, run:f\n",
      "3460/1500, run:f\n",
      "3470/1500, run:f\n",
      "3480/1500, run:f\n",
      "3490/1500, run:f\n",
      "3500/1500, run:f\n",
      "3510/1500, run:f\n",
      "3520/1500, run:f\n",
      "3530/1500, run:f\n",
      "3540/1500, run:f\n",
      "3550/1500, run:f\n",
      "3560/1500, run:f\n",
      "3570/1500, run:f\n",
      "3580/1500, run:f\n",
      "3590/1500, run:f\n",
      "3600/1500, run:f\n",
      "3610/1500, run:f\n",
      "3620/1500, run:f\n",
      "3630/1500, run:f\n",
      "3640/1500, run:f\n",
      "3650/1500, run:f\n",
      "3660/1500, run:f\n",
      "3670/1500, run:f\n",
      "3680/1500, run:f\n",
      "3690/1500, run:f\n",
      "3700/1500, run:f\n",
      "3710/1500, run:f\n",
      "3720/1500, run:f\n",
      "3730/1500, run:f\n",
      "3740/1500, run:f\n",
      "3750/1500, run:f\n",
      "3760/1500, run:f\n",
      "3770/1500, run:f\n",
      "3780/1500, run:f\n",
      "3790/1500, run:f\n",
      "3800/1500, run:f\n",
      "3810/1500, run:f\n",
      "3820/1500, run:f\n",
      "3830/1500, run:f\n",
      "3840/1500, run:f\n",
      "3850/1500, run:f\n",
      "3860/1500, run:f\n",
      "3870/1500, run:f\n",
      "3880/1500, run:f\n",
      "3890/1500, run:f\n",
      "3900/1500, run:f\n",
      "3910/1500, run:f\n"
     ]
    }
   ],
   "source": [
    "EmbeddingFetcher = GetBERTEmbeddings(d['full_text'],'model/deberta-v3-large')\n",
    "EmbeddingFetcher.inf(stop=1500,SeqLen = 512 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear cuda cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del EmbeddingFetcher.model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = EmbeddingFetcher.GetEmbeddings('CLS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [np.array(i).reshape(1024) for i in x]\n",
    "columns = ['cohesion', 'syntax', 'vocabulary','phraseology', 'grammar', 'conventions']\n",
    "TrainX,TestX = x[:2800],x[2800:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainY,TestY = [],[]\n",
    "for i in columns:\n",
    "    TrainY.append(d[i].iloc[:2800])\n",
    "    TestY.append(d[i].iloc[2800:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\"random_state\":trial.suggest_categorical(\"random_state\", [42]),           \n",
    "        'learning_rate' : trial.suggest_float('learning_rate', 0.01, 1),  \n",
    "        \"max_depth\" : trial.suggest_int(\"max_depth\", 5, 15),\n",
    "        \"alpha\" : trial.suggest_float('alpha',0.9,1),\n",
    "    }\n",
    "    error = []\n",
    "    for i in range(6):\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(TrainX,TrainY[i])\n",
    "        PredY = model.predict(TestX)\n",
    "        e = mean_squared_error(TestY[i],PredY,squared=False)\n",
    "        error.append(e)\n",
    "    mcrmse = sum(error)/6\n",
    "    return mcrmse\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization.matplotlib import plot_optimization_history\n",
    "plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48930992011706814,\n",
       " [0.5236888878939432,\n",
       "  0.4829607151914506,\n",
       "  0.4378622568825183,\n",
       "  0.4774016171738794,\n",
       "  0.5231214299712789,\n",
       "  0.49082461358933865])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective():\n",
    "    params = {          \n",
    "        'learning_rate' : 0.042,                   \n",
    "    }\n",
    "    error = []\n",
    "    for i in range(6):\n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(TrainX,TrainY[i])\n",
    "        PredY = model.predict(TestX)\n",
    "        e = mean_squared_error(TestY[i],PredY,squared=False)\n",
    "        error.append(e)\n",
    "    mcrmse = sum(error)/6\n",
    "    return mcrmse,error\n",
    "objective()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "593988f55108e9a22df825be697685e2e60f0c546ce2b7da78c95a16021f878c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
