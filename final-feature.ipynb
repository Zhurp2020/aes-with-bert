{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file is responsible for feature extraction in the SHU data, including embeddings, complexity measures, similarity measures and verb-argument constructions\n",
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\GIGA\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\outdated\\utils.py:14: OutdatedPackageWarning: The package outdated is out of date. Your version is 0.2.1, the latest is 0.2.2.\n",
      "Set the environment variable OUTDATED_IGNORE=1 to disable these warnings.\n",
      "  return warn(\n"
     ]
    }
   ],
   "source": [
    "%run functions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader()\n",
    "d = loader.GetData('final')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text, remove redundant whitespace, \\n, and 's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = []\n",
    "preproc = preprocessing.make_pipeline(preprocessing.normalize.whitespace)\n",
    "for essay in d['text']:\n",
    "    essay = preproc(essay.replace('\\n',''))\n",
    "    punct = [':',',','.','?',';',\"'\",'!']\n",
    "    for p in punct:\n",
    "        essay = essay.replace(p,p+' ')\n",
    "    for p in [' ' + i for i in punct]:\n",
    "        essay = essay.replace(p,p.lstrip()) \n",
    "    cleaned = preproc(essay.replace('\\n',''))\n",
    "    clean_text.append(cleaned)\n",
    "d['text'] = clean_text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get bert embeddings\n",
    "21m 34.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xa\n",
    "for i in range(0,4000,1000):\n",
    "    if i == 3000:\n",
    "        end = len(d)\n",
    "    else:\n",
    "        end = i+1000\n",
    "    EmbeddingFetcher = GetBERTEmbeddings(d['text'][i:end],'model/deberta-v3-large')\n",
    "    EmbeddingFetcher.inf(stop=1000,SeqLen = 512)\n",
    "    xp.append(EmbeddingFetcher.GetEmbeddings('MeanP')) \n",
    "    del EmbeddingFetcher\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to disk\n",
    "### Mean pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(xa,'features/final-meanp.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract fine-grained complexity features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "135m56.1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(d)):\n",
    "    t = d['text'][i]\n",
    "    if len(t) > 2:\n",
    "        extractor = FeatureExtraction(t)\n",
    "        extractor.process()\n",
    "        features = extractor.get_data()\n",
    "        with open('features/final-winter-fine.csv','a',encoding='utf-8') as f:\n",
    "            f.write('{},{},'.format(i,d['学号'][i]))\n",
    "            f.write(','.join([str(i) for i in features]))\n",
    "            f.write('\\n')\n",
    "    else:\n",
    "        with open('features/final-winter-fine.csv','a',encoding='utf-8') as f:\n",
    "            f.write('{},'.format(i))\n",
    "            f.write('\\n')\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract syntactic similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_list = []\n",
    "for num in range(len(d)):\n",
    "    doc = NLP(d['text'][num])\n",
    "    sents = [j for j in doc.sents if len([i for i in str(j).split() if i.isalpha()]) > 3]  \n",
    "    self_sim = [1 for i in range(len(sents))] \n",
    "    sim_matrix= np.eye(len(sents),len(sents))\n",
    "    for i in range(len(sents)):\n",
    "        self_sim[i] = PartialTreeKernel(sents[i],sents[i])\n",
    "        if self_sim[i] == 0:\n",
    "            self_sim[i] = 1\n",
    "    for i in range(len(sents)):\n",
    "        for j in range(i+1,len(sents)):\n",
    "            sim_matrix[i,j] = PartialTreeKernel(sents[i],sents[j])/math.sqrt(self_sim[i]*self_sim[j])\n",
    "    #if num % 10 == 0:\n",
    "    print(num)\n",
    "    sim_list.append(sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('features/final_winter_sent.npz',*sim_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract verb-vac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacs = []\n",
    "for i in range(len(d)):\n",
    "    doc = NLP(d['text'][i])\n",
    "    doc_verb_vac = GetVAC(doc,render=False)\n",
    "    for v in doc_verb_vac:\n",
    "        if 'oprd' in v[0]:\n",
    "            print(i,v)\n",
    "    vacs.append(doc_verb_vac)\n",
    "    if i % 50 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('features/final-verbvac.txt','w',encoding='utf-8') as f:\n",
    "    for line in vacs:\n",
    "        f.write((', '.join([i[0] for i in line])))\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "593988f55108e9a22df825be697685e2e60f0c546ce2b7da78c95a16021f878c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
