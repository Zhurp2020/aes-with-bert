{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%run utils.ipynb\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from thinc.api import set_gpu_allocator, require_gpu\n",
    "set_gpu_allocator(\"pytorch\")\n",
    "require_gpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader()\n",
    "d = loader.GetData('final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GIGA\\AppData\\Local\\Temp\\ipykernel_23336\\2064060296.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  d['text'][i]= d['text'][i].replace(\"'\",\"' \")\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(d)):\n",
    "    d['text'][i]= d['text'][i].replace(\"'\",\"' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetAllComb(n,NumList):\n",
    "    # Get all subsets of length n in the given list, and in the original order\n",
    "    res = []\n",
    "    if n == 1: # [0,1,2] --> [[0],[1],[2]]\n",
    "        return [[i] for i in NumList]\n",
    "    if n == len(NumList): # [0,1,2] --> [0,1,2]\n",
    "        return [[i for i in NumList]]\n",
    "    if n >= 2: # for each element before len(NumList)-n, insert that element into position 0 for all subsets of length n-1 of the remaining elements\n",
    "        for start in range(len(NumList)-n+1): \n",
    "            # (3,[0,1,2,3,4])\n",
    "            last = GetAllComb(n-1,NumList[start+1:])\n",
    "            # 0 + (2,[1,2,3,4]), 1 + (2,[2,3,4]), 2 + (2,[3,4])\n",
    "            for comb in last:\n",
    "                comb.insert(0,NumList[start])\n",
    "            res += last\n",
    "        return res\n",
    "def KernelFunction(tree1,tree2):\n",
    "    # tree1 and tree2 are actually trees of token objects\n",
    "    # get dep labels of all nodes, t1 and t2 are trees of dep labels\n",
    "    t1 = (tree1[0].dep_,[i.dep_ for i in tree1[1] if i])\n",
    "    t2 = (tree2[0].dep_,[i.dep_ for i in tree2[1] if i])\n",
    "    # mu and lambda are decay factors, mu penalize tree height and lambda penalize tree length\n",
    "    mu = 0.4\n",
    "    lambda_ = 0.4\n",
    "    k = 0 # final sum\n",
    "    if t1[0] == t2[0]: # if labels are the same\n",
    "        for tree_len in range(1,min(len(t1[1]),len(t2[1]))) :\n",
    "            # length of all possible subtrees \n",
    "            prod = 1 # product\n",
    "            ChildSeqs = GetAllComb(tree_len,[c for c in range(tree_len)])\n",
    "            # list of indices of all possible child sequences of given length\n",
    "            for j1 in ChildSeqs:\n",
    "                for j2 in ChildSeqs:\n",
    "                    # Get all pairs of sub sequences\n",
    "                    for i in range(tree_len):\n",
    "                        childt1 = tree1[1][j1[i]] # token object\n",
    "                        childt2 = tree2[1][j2[i]]\n",
    "                        prodt1 = (tree1[0],[j for j in childt1.children if j]) # build subtree \n",
    "                        prodt2 = (tree2[0],[j for j in childt2.children if j])\n",
    "                        prod = prod * KernelFunction(prodt1,prodt2) \n",
    "                        # continue matching subtree\n",
    "                    # finish matching indices j1 and j2, sum \n",
    "                    dt1 = j1[-1] - j1[0] + 1\n",
    "                    dt2 = j2[-1] - j2[0] + 1    \n",
    "                    k += (lambda_) ** (dt1 + dt2) * prod\n",
    "        return mu * (lambda_**2 + k)\n",
    "    else:\n",
    "        return 0\n",
    "def PartialTreeKernel(tree1,tree2):\n",
    "    sim = 0\n",
    "    for tokent1 in tree1:\n",
    "        prodt1 = (tokent1,[i for i in tokent1.children if i])\n",
    "        for tokent2 in tree2:\n",
    "            # sum over all nodes\n",
    "            prodt2 = (tokent2,[i for i in tokent2.children if i])\n",
    "            if tokent1.text.isalpha() and (tokent1.dep_ == tokent2.dep_):\n",
    "                sim += KernelFunction(prodt1,prodt2)\n",
    "    return sim \n",
    "def normPTK(tree1,tree2):\n",
    "    return PartialTreeKernel(tree1,tree2)/math.sqrt(PartialTreeKernel(tree1,tree1)*PartialTreeKernel(tree2,tree2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLP = spacy.load('en_core_web_trf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n",
      "250\n",
      "300\n",
      "350\n",
      "400\n",
      "450\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n",
      "800\n",
      "850\n",
      "900\n",
      "950\n",
      "1000\n",
      "1050\n",
      "1100\n",
      "1150\n",
      "1200\n",
      "1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (662 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300\n",
      "1350\n",
      "1400\n",
      "1450\n",
      "1500\n",
      "1550\n",
      "1600\n",
      "1650\n",
      "1700\n",
      "1750\n",
      "1800\n",
      "1850\n",
      "1900\n",
      "1950\n",
      "2000\n",
      "2050\n",
      "2100\n",
      "2150\n",
      "2200\n",
      "2250\n",
      "2300\n",
      "2350\n",
      "2400\n",
      "2450\n",
      "2500\n",
      "2550\n",
      "2600\n",
      "2650\n",
      "2700\n",
      "2750\n",
      "2800\n",
      "2850\n",
      "2900\n",
      "2950\n",
      "3000\n",
      "3050\n",
      "3100\n",
      "3150\n",
      "3200\n",
      "3250\n",
      "3300\n",
      "3350\n",
      "3400\n",
      "3450\n",
      "3500\n",
      "3550\n",
      "3600\n",
      "3650\n",
      "3700\n",
      "3750\n",
      "3800\n"
     ]
    }
   ],
   "source": [
    "sim_list = []\n",
    "for num in range(len(d)):\n",
    "    doc = NLP(d['text'][num])\n",
    "    sents = [j for j in doc.sents if len(str(j).split()) > 5 ]   \n",
    "    sim_matrix= np.eye(len(sents),len(sents))\n",
    "    for i in range(len(sents)):\n",
    "        for j in range(i+1,len(sents)):\n",
    "            sim_matrix[i,j] = normPTK(sents[i],sents[j])\n",
    "    if num % 50 == 0:\n",
    "        print(num)\n",
    "    sim_list.append(sim_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('final_winter_sent.npz',*sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = np.load('features/final_winter_sent.npz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
